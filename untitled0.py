# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12-0_c54VvtVKxN9mE9DefhvNgDT8T9ca
"""

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import tensorflow as tf

# Membaca data MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Menampilkan jumlah dataset
total_samples = len(x_train) + len(x_test)
print(f"Jumlah dataset: {total_samples}")
print(f"Jumlah data training: {len(x_train)}")
print(f"Jumlah data test: {len(x_test)}")

# Mengubah ke format gambar (samples, 28, 28, 1)
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Mengubah ke one-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Memisahkan dataset menjadi 80% train set dan 20% validation set
split_index = int(0.8 * len(x_train))
x_train, x_val = x_train[:split_index], x_train[split_index:]
y_train, y_val = y_train[:split_index], y_train[split_index:]

# Menampilkan informasi tentang pembagian dataset
print(f"\nPembagian dataset:")
print(f"   - Training set: {split_index} samples (80%)")
print(f"   - Validation set: {len(x_val)} samples (20%)")

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=(28, 28, 1)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=3)

history = model.fit(x_train, y_train,
                    batch_size=128,
                    epochs=10,
                    verbose=1,
                    validation_data=(x_val, y_val),
                    callbacks=[early_stopping])

# Plotting accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plotting loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Menentukan nama file output
output_file = "mnist_model.tflite"

# Mengekspor model ke dalam format TF-Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Menyimpan model ke dalam file output
with open(output_file, 'wb') as f:
    f.write(tflite_model)

print("\nModel berhasil disimpan ke dalam format TF-Lite:", output_file)